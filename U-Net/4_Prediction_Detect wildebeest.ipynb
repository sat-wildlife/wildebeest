{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4x9H2wJ1m7j"
   },
   "source": [
    "## Load libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101276,
     "status": "ok",
     "timestamp": 1706781768070,
     "user": {
      "displayName": "Zijing Wu",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "rHYQ6yZ5R-TL",
    "outputId": "2390b6e2-958d-45fe-b304-c07e9beab7dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the GPU colab assigns to you\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.device('/device:GPU:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13738,
     "status": "ok",
     "timestamp": 1706782085508,
     "user": {
      "displayName": "Zijing Wu",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "mW60uNlcTOd9",
    "outputId": "cba3dee4-0af9-43fd-c9f5-4fe53dca48df"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "#import rasterio.warp             # Reproject raster samples\n",
    "from rasterio import windows\n",
    "#import geopandas as gps\n",
    "#import PIL.Image\n",
    "#import PIL.ImageDraw\n",
    "\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# !pip install ipython-autotime\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6356,
     "status": "ok",
     "timestamp": 1706782091827,
     "user": {
      "displayName": "Zijing Wu",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "1hoOpPmE1hl4",
    "outputId": "7b9934d9-c845-438a-9a88-22486f61ce27"
   },
   "outputs": [],
   "source": [
    "#set the sys path where the modules locates\n",
    "import sys\n",
    "sys.path.insert(0,\"core\")\n",
    "\n",
    "#If you are using Google Colaboratory, modify the path here\n",
    "#sys.path.insert(0,\"/content/drive/MyDrive/Colab/zijingwu-Satellite-based-monitoring-of-wildebeest/core\")\n",
    "from preprocess import *\n",
    "from data_generator import DataGenerator, SimpleDataGenerator\n",
    "\n",
    "from model import *\n",
    "\n",
    "from evaluation import *\n",
    "\n",
    "from visualization import *\n",
    "\n",
    "import importlib\n",
    "\n",
    "from predict import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsAE_u0QpMfa"
   },
   "source": [
    "## Load the satellite images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Data_folder = \"/home/zijing/wildebeest/data/test\"\n",
    "\n",
    "image_path = Data_folder\n",
    "\n",
    "Folder = \"/home/zijing/wildebeest/tmp\"\n",
    "\n",
    "Output_dir = os.path.join(Data_folder,\"predict_test\")\n",
    "Final_Output_dir =  os.path.join(Data_folder,\"predict_test_combine\")\n",
    "\n",
    "WEIGHT_PATH = os.path.join(Folder,'checkpoint/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1277,
     "status": "ok",
     "timestamp": 1706782249317,
     "user": {
      "displayName": "Zijing Wu",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "4UcHj6VkIUrk",
    "outputId": "e8f80b55-4f12-41e8-d0d6-876d38432251"
   },
   "outputs": [],
   "source": [
    "target_images = get_images_to_predict(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706782243628,
     "user": {
      "displayName": "Zijing Wu",
      "userId": "12694382704677250833"
     },
     "user_tz": -480
    },
    "id": "CkjPW2jtXVnv",
    "outputId": "da5ccd1c-5700-480c-ef0f-270fd4a4ac50"
   },
   "outputs": [],
   "source": [
    "NUM = 2\n",
    "PATCH_SIZE = 336\n",
    "TILE_MAX_SIZE = PATCH_SIZE * NUM\n",
    "\n",
    "INPUT_BANDS = [0,1,2]\n",
    "NUMBER_BANDS=len(INPUT_BANDS)\n",
    "\n",
    "CONTRAST = False\n",
    "fold_nums = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQxlg_ALTK3J"
   },
   "source": [
    "## Detect the wildebeest on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_size = 16\n",
    "nfold = 5\n",
    "\n",
    "\n",
    "if not os.path.exists(Output_dir):\n",
    "    os.makedirs(Output_dir)\n",
    "if not os.path.exists(Final_Output_dir):\n",
    "    os.makedirs(Final_Output_dir)\n",
    "    \n",
    "for ti in target_images:\n",
    "    print(ti)\n",
    "    f = ti\n",
    "    file_name = os.path.split(f)[1]\n",
    "    img_name, file_extension = os.path.splitext(file_name)\n",
    "    print(img_name)\n",
    "\n",
    "    final_shp_path = os.path.join(Final_Output_dir, img_name+'.shp')\n",
    "    final_mask_path = os.path.join(Final_Output_dir, img_name+'.tif')\n",
    "\n",
    "    if Path(final_shp_path).is_file() == True:\n",
    "      print(f\"Prediction already exists. Skip.\")\n",
    "      continue\n",
    "\n",
    "    with rasterio.open(f) as src:\n",
    "\n",
    "\n",
    "        model = unet(pretrained_weights=None, input_size=(PATCH_SIZE,PATCH_SIZE,NUMBER_BANDS), regularizers = regularizers.l2(0.0001))\n",
    "        detectedMask = detect_wildebeest(model, WEIGHT_PATH, src, width=PATCH_SIZE, height=PATCH_SIZE, stride = 256,\n",
    "                            batch_size=12, stretch=CONTRAST, num_folds=nfold) # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "        # visualize_prediction(detectedMask)\n",
    "        #Write the mask to file\n",
    "        # visualize_data(np.moveaxis(np.uint8(src.read()), 0,-1),np.expand_dims(detectedMask, axis=2))\n",
    "        writeResultsToDisk(detectedMask, src, src.meta['transform'], final_shp_path, None, cluster_size)\n",
    "        #Write the mask to file\n",
    "        # visualize_data(np.moveaxis(np.uint8(src.read()), 0,-1),np.expand_dims(detectedMask, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UJNHV04YU_j",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If the satellite image size is too large and you would like to process in tiles:\n",
    "\n",
    "cluster_size = 16\n",
    "nfold = 5\n",
    "\n",
    "\n",
    "if not os.path.exists(Output_dir):\n",
    "    os.makedirs(Output_dir)\n",
    "if not os.path.exists(Final_Output_dir):\n",
    "    os.makedirs(Final_Output_dir)\n",
    "    \n",
    "for ti in target_images:\n",
    "    print(ti)\n",
    "    f = ti\n",
    "    file_name = os.path.split(f)[1]\n",
    "    img_name, file_extension = os.path.splitext(file_name)\n",
    "    print(img_name)\n",
    "\n",
    "    ti_Output_dir = os.path.join(Output_dir, img_name)\n",
    "    if not os.path.exists(ti_Output_dir):\n",
    "        os.makedirs(ti_Output_dir)\n",
    "    final_shp_path = os.path.join(Final_Output_dir, img_name+'.shp')\n",
    "    final_mask_path = os.path.join(Final_Output_dir, img_name+'.tif')\n",
    "\n",
    "    if Path(final_shp_path).is_file() == True:\n",
    "      print(f\"Prediction already exists. Skip.\")\n",
    "      continue\n",
    "\n",
    "    with rasterio.open(f) as src:\n",
    "\n",
    "\n",
    "        model = unet(pretrained_weights=None, input_size=(PATCH_SIZE,PATCH_SIZE,NUMBER_BANDS), regularizers = regularizers.l2(0.0001))\n",
    "        detect_wildebeest_tile(model, WEIGHT_PATH, src, ti_Output_dir, f, tile_width=5000, tile_height=5000, \n",
    "                               width=PATCH_SIZE, height=PATCH_SIZE, stride = 256,\n",
    "                               batch_size=12, stretch=CONTRAST, num_folds=nfold,\n",
    "                               mask_outpath=None, cluster_size=cluster_size)\n",
    "                               \n",
    "        \n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(ti_Output_dir, topdown=False):\n",
    "        for name in files:\n",
    "          _, file_extension = os.path.splitext(name)\n",
    "          if file_extension == '.shp':\n",
    "            #print(name)\n",
    "                  \n",
    "            points = gpd.read_file(os.path.join(root,name))\n",
    "            file_list.append(points)\n",
    "    # print(len(file_list))\n",
    "    rdf = gpd.pd.concat(file_list, ignore_index=True)\n",
    "    \n",
    "    rdf.to_file(final_shp_path)   \n",
    "    print(f\"Number of detected wildebeest on image {img_name} is: {rdf.count()['id']}\")\n",
    "    # del detectedMask\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
